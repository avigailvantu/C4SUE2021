{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 10\n",
    "## Plotting Points data: 311 data ðŸ“² ðŸ“² ðŸ“² ðŸ“² \n",
    "\n",
    "c4sue 2021 NYU @avigailvantu\n",
    "\n",
    "Today we will continue to work with Pandas and Matplotlib. We will also create some maps using geopandas. Looking into 311 complaints from the past month and from the same period in 2021 we will compare, group and visualize the cityâ€™s trends. Along the way we will create a GeoDataFrame, this is a geographical format that is similar enough to a data frame but has an extra dimension of geographical attributes to it.  Think of the times where we loaded a CSV data into QGIS and needed to merge with a swapfile of assign column to a geographical unit.\n",
    "\n",
    "This week we will be doing something similar, only with that we will transform a csv (which we will read into a data frame) and then assign columns in the data to represent geometry. That would enable us to then visualize the data quite easily. Weâ€™ll some pretty simple, yet cool, ways to do so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing GeoPandas: \n",
    "\n",
    "Before getting started with today's class you will need to download the GeoPandas library (in case you don't have it already). The easiest way is to follow the intructions on the library page:\n",
    "\n",
    "https://geopandas.org/getting_started.html \n",
    "\n",
    "If you are facing issues installing through Codna you can create a new enviorment. There are some details about it on the GeoPandas page. In addition, there are more instructions inside the \"class 10\" folder on Github. \n",
    "\n",
    "https://github.com/avigailvantu/c4sue2021/tree/main/labs/class_10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "#from shapely.geometry import Point\n",
    "#from geopandas import GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment I downloaded the 311 data from the NYC Open Data platform. I wanted to look into how people in the city complaint patterns were in the past month. In order to get a relative understating we will compare data from 2020 and 2021. Comparing similar periods in between years is a common method in highlighting changes and trends. Thinking about time series, many phenomenas are seasonal. Which is why comparing one month to the previous month is tricky. Having said that, even the same period in two separate years is likely to have some differences, but hopefully less. \n",
    "\n",
    "\n",
    "- Data 2020: March 1st - March 31st 2020\n",
    "- Data 2021: March 1st - March 31st 2021 \n",
    "\n",
    "* Note: you will need to fetch the data yourself from the NYC Open Data Flatrform \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 311 data 1 for this year and one for last year: \n",
    "data20 = pd.read_csv('311_March2020.csv')\n",
    "data21 = pd.read_csv('311_March2021.csv')\n",
    "\n",
    "#load 2020 data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data20.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data21.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('shape 2020',data20.shape)\n",
    "print ('shape 2021',data21.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "What are the changes between 2020 and 2021 data in terms of quantities of non emargency complaints in NYC? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the columns in the data? \n",
    "print ('2020 columns:',data20.columns)\n",
    "print ('2021 columns:',data21.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 311 data for 2020 and 2021 data by agency: \n",
    "\n",
    "Let's look into the \"value_counts\" function. That would return the number of values for each value in the Agencey column. Meaning we will get a list of how many complaints were chanaled into each agency. \n",
    "\n",
    "Check out this URL for the agencies acronyms\n",
    "https://www1.nyc.gov/site/mocs/about/agencies-acronyms-initialisms.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data20['Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data21['Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "- What are some of the differences in patterns we are seeing in which agencies the calls have been channeled to between 2020 and 2021?  Which agencies have been seeing less activity and which ones more? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we worked mainly with Pandas (also some pyplot, numpy and datetime). In addiition to all these liberals Pyhton also has some pretty neat geographical features! Let's check out a few of them on our data: \n",
    "\n",
    "## From DataFrame to GeoDataFrame ðŸ§®\n",
    "\n",
    "GeoDataFrame is a data frame that includes one column with a \"special\" status. This column is the \"geometry\" column which enbales Python to refer to the data as geogpraphical. In many cases, like in our case, we will not have the \"geometry\" column built-in in the data. Instead, we will usually have x any y or Latitue and Longtitude that we will tranform into the needed format. \n",
    "\n",
    "To go from DataFrame---> GeoDataFrame:\n",
    "- we would want to tell python which columns can be used as \"geometry\". \n",
    "\n",
    "Note that for point type data a typical geometry columns looks like this\n",
    "\n",
    "\n",
    "- POINT (LON LAT) \n",
    "\n",
    "The point() format will be created using the GeoDataFrame function. We will only need to tell Python which columns in the data are which (lon, lat).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data into geo data frame: \n",
    "\n",
    "\n",
    "#one geodata frame for 2020 \n",
    "gdf20 = gpd.GeoDataFrame(\n",
    "    data20, geometry=gpd.points_from_xy(data20.Longitude, data20.Latitude))\n",
    "\n",
    "#and another one for 2021 \n",
    "gdf21 = gpd.GeoDataFrame(\n",
    "    data21, geometry=gpd.points_from_xy(data21.Longitude, data21.Latitude))\n",
    "\n",
    "#note that here we tell Python that the column: \n",
    "#data20.Longitude is the longtitute and data20.Latitude is the latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame\n",
    "\n",
    "data20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and GeoDataFrame\n",
    "#check out our GeoDataFrame--> note the \"geometry\" column was added (all the way to the right)\n",
    "gdf20.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the data: \n",
    "\n",
    "gdf20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf21.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can fianly visualize the data: \n",
    "\n",
    "First: plot all points for the layer, not I am setting the marker zise on 0.3 since there are so many of them!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all 2020 data:\n",
    "gdf20.plot( color='red',legend=True,figsize=(12, 12),markersize=0.1)\n",
    "plt.axis('off')\n",
    "plt.title('311 complaints March 2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all 2020 data: \n",
    "gdf21.plot( color='blue',legend=True,figsize=(12, 12),markersize=0.1)\n",
    "plt.axis('off')\n",
    "plt.title('311 complaints March 2021')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exmine one agency: \n",
    "### HPD (Housing Preservation & Development)\n",
    "\n",
    "In order to make better sense of what are people reporting less in these past weeks, we will take a closer look at the different agencies complaints. \n",
    "\n",
    "We will start with HPD: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only hpd\n",
    "\n",
    "hpd20 = gdf20.loc[gdf20['Agency']=='HPD']\n",
    "\n",
    "hpd21 = gdf21.loc[gdf21['Agency']=='HPD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(hpd20))\n",
    "print (len(hpd21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot HPD data for both 2020 and 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd20.plot( color='blue',legend=True,figsize=(12, 12), markersize=1)\n",
    "plt.axis('off')\n",
    "plt.title('311 HPD complaints March 2020')\n",
    "hpd21.plot( color='red',legend=True,figsize=(12, 12),markersize=1)\n",
    "plt.axis('off')\n",
    "plt.title('311 HPD complaints March 2021')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Which areas seem to have more or less HPD complaints between March 2020 and March 2021?\n",
    " \n",
    "## Another way for us to look into the data is to sub-slice it again: \n",
    "\n",
    "Now dive into the complaint types in the HPD complaints. So we can learn what are the types of housing complaint we are seeing. that would also help us compare what were some of the changes b/w both periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot hpd by complaint type:\n",
    "\n",
    "#1. for 2020\n",
    "ax = hpd20.plot(column='Complaint Type',legend=True,figsize=(12, 12), alpha = 0.6,markersize=2)\n",
    "#we can also visualize HPD complaints based on the complaint type: \n",
    "plt.title('311 HPD complaints March 2020 by Complaint type')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#2. for 2020 \n",
    "ax = hpd21.plot(column='Complaint Type',legend=True,figsize=(12, 12),alpha = 0.6,markersize=2)\n",
    "#we can also visualize HPD complaints based on the complaint type: \n",
    "plt.title('311 HPD complaints March 2021 by Complaint type')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: \n",
    "\n",
    "What information can we take away from these two maps? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way to look into the complaint types: \n",
    "On top of visualizng the data we can also look into the number of complaints of each type. An easy way to do so is to use the Group.by command. This is a pretty timple command that has a lot of options (more about it on other classes!). \n",
    "\n",
    "The main thing to know about group.by right now is that group.by operates on a dataframe so that it basically does 3 main things: \n",
    "\n",
    "1. Split : take the data and splits it according to the grouping condition \n",
    "2. Apply: calculates what we want it to do: sum, means count etc\n",
    "3. Combine: it combines the data into new groups \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd20['Complaint Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hpd20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hpd21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we will count group by complaint type so that: Python will Split the data according to each type of complaint (hot water, windows etc). Then it will Apply, meaning it would count how many of each compliant type the data has. Finally, Python will Combine the new grouped data. So in our case that would be number of complaints per each complaint type. Note that by doing so, our data frame structure will changes completely so that each row will represent a complaint type, and the data in the cells will be the count of how many of them are there in our data.  All that in one line of code :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group.by hpd complaints \n",
    "\n",
    "#1. for 2019\n",
    "hpd20_count_type = hpd20.groupby(['Complaint Type']).count()\n",
    "#1. for 2020\n",
    "hpd21_count_type = hpd21.groupby(['Complaint Type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at out new data for 2019 \n",
    "hpd20_count_type.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and for 2020\n",
    "hpd21_count_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because the all columns look the same we will remove them and only keep the first one\n",
    "\n",
    "hpd20_count_type = hpd20_count_type['Unique Key']\n",
    "hpd21_count_type = hpd21_count_type['Unique Key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd20_count_type.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's see the most common HPD complaints for both March/April 2020 and 2021:\n",
    "\n",
    "# sort data \n",
    "\n",
    "hpd20_count_type = hpd20_count_type.sort_values()\n",
    "\n",
    "hpd21_count_type = hpd21_count_type.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 most common complaints in 2020 were: \n",
    "hpd20_count_type.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#5 most common complaints in 2021  were: \n",
    "hpd21_count_type.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:\n",
    "\n",
    "Your turn: \n",
    "\n",
    "So far we worked on the HPD data. \n",
    "\n",
    "We will now divide into groups, when each group will look into another agency complaints: \n",
    "\n",
    "# Group 1: NYPD\n",
    "# Group 2: DOT \n",
    "# Group 3: DEP \n",
    "# Group 4: DSNY \n",
    "# Group 5: DOHMH \n",
    "\n",
    "For each groups: \n",
    "\n",
    "1. Please filter the subset of the data that has *YOUR* Agencey name\n",
    "2. Plot, summarize and group.by the data for both 2020 and 2021 \n",
    " \n",
    "Deliver:  \n",
    "- a. What are the patterns in *YOUR* agency complaints between the 2020 and 2021 data? \n",
    "- b. What are some geogrpaphical patterns you are seeing comparing both years?\n",
    "\n",
    "In class: present your main findings. For you homework: submit your jupyter notebook. In addition on your NYU classes submissions write a short summary of your findings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
